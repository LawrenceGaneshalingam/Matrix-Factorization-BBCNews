{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c4199d2-0a4a-4382-b614-da4ca09b27a6",
   "metadata": {},
   "source": [
    "## Part 2: Limitations of sklearn’s Non-Negative Matrix Factorization Library \n",
    "\n",
    "    Author: Lawrence Ganeshalingam\n",
    "    Date: November 23, 2025\n",
    "    Assignment: Kaggle BBC News Classification Competition (Unsupervised Matrix Factorization Approach)\n",
    "    Subject: CSCA-5632 Week-4 Lab Part 1\n",
    "    email: lawrence.ganeshlingam@colorado.edu\n",
    "    Github: https://github.com/LawrenceGaneshalingam/Matrix-Factorization-BBCNews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b7947a-4d4d-4552-9858-10a861a0c8a0",
   "metadata": {},
   "source": [
    "### Lab Report: Limitations of sklearn’s NMF Library (Part 2) \n",
    "\n",
    "#### 1. Loading Data, Applying NMF, Predicting Ratings, and Measuring RMSE\n",
    "I started by pulling in the movie ratings from the HW3 recommender system setup, using the train data (with 700146 entries for uID, mID, rating) to build the model and the test data (300063 entries) to check predictions. I turned them into user-item matrices, aligned the shared users and movies, and plugged in zeros for missing spots since NMF needs non-negative values.\n",
    "\n",
    "For the model, I went with sklearn's NMF using KL loss (beta_loss='kullback-leibler', solver='mu' to make it work), set n_components to 20, init as 'random', and max_iter at 200. I fitted it on the train matrix to get the W (user-latent) and H (latent-item) parts, then rebuilt the predictions with pred_matrix = W @ H.\n",
    "\n",
    "To get the RMSE, I focused on the actual non-zero spots in the test data: it came out to 2.8775. I also tuned n_components across [10,20,30]: RMSE was 2.779 for 10, 2.721 for 20, and 2.712 for 30, best at 30."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e500a-1426-4aad-8ab4-7c124ddd612f",
   "metadata": {},
   "source": [
    "#### Library, setup, data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1630f733-2b87-4efe-9b12-c58555e22e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library & setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "255caad4-7d16-474c-8634-225c012daa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('C:/CUBoulder/MSAI/CSCA5632/Week-3/train.csv')\n",
    "test_data = pd.read_csv('C:/CUBoulder/MSAI/CSCA5632/Week-3/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57ab8e02-f90b-4c48-b8d3-c54d6cf02538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 700146 entries, 0 to 700145\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype\n",
      "---  ------  --------------   -----\n",
      " 0   uID     700146 non-null  int64\n",
      " 1   mID     700146 non-null  int64\n",
      " 2   rating  700146 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 16.0 MB\n",
      "None\n",
      "Test data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300063 entries, 0 to 300062\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype\n",
      "---  ------  --------------   -----\n",
      " 0   uID     300063 non-null  int64\n",
      " 1   mID     300063 non-null  int64\n",
      " 2   rating  300063 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 6.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data info:\")\n",
    "print(train_data.info())\n",
    "print(\"Test data info:\")\n",
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f108689-ea17-4178-85aa-fc70a6415de5",
   "metadata": {},
   "source": [
    "#### Pivot to user-item matrices (fill missing with 0 for NMF, as it requires non-negative input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c5ecffd-b4d7-465a-ade4-9465a780e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned train matrix shape: (6040, 3496)\n",
      "Aligned test matrix shape: (6040, 3496)\n"
     ]
    }
   ],
   "source": [
    "# Pivot to user-item matrices (fill missing with 0 for NMF, as it requires non-negative input)\n",
    "train_matrix = train_data.pivot(index='uID', columns='mID', values='rating').fillna(0)\n",
    "test_matrix = test_data.pivot(index='uID', columns='mID', values='rating').fillna(0)\n",
    "\n",
    "# Align to common users/movies for consistent comparison (handle differing shapes)\n",
    "common_users = train_matrix.index.intersection(test_matrix.index)\n",
    "common_movies = train_matrix.columns.intersection(test_matrix.columns)\n",
    "train_matrix = train_matrix.loc[common_users, common_movies]\n",
    "test_matrix = test_matrix.loc[common_users, common_movies]\n",
    "\n",
    "print(\"Aligned train matrix shape:\", train_matrix.shape)\n",
    "print(\"Aligned test matrix shape:\", test_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d21ae-6faa-474a-885a-ef1bb9244b30",
   "metadata": {},
   "source": [
    "#### Apply sklearn NMF (technique: NMF with KL loss for sparsity; hyperparams: n_components=20 as starting point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb7bad3a-02a8-4adb-9177-6f4b30e257cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (sklearn NMF): 2.8775332768905897\n"
     ]
    }
   ],
   "source": [
    "# Apply sklearn NMF (technique: NMF with KL loss for sparsity; hyperparams: n_components=20 as starting point)\n",
    "n_components = 20  # Latent factors; can tune (e.g., try 10-50)\n",
    "nmf = NMF(n_components=n_components, init='random', random_state=42, max_iter=200, beta_loss='kullback-leibler', solver='mu')  # For 'kullback-leibler' loss, must use solver='mu' (changed from default 'cd', which doesn't support KL and caused ValueError; 'mu' enables multiplicative update for divergence losses like KL, fixing compatibility)\n",
    "W = nmf.fit_transform(train_matrix)  # User-latent matrix\n",
    "H = nmf.components_  # Latent-item matrix\n",
    "pred_matrix = np.dot(W, H)  # Reconstructed predictions for all entries\n",
    "\n",
    "# Measure RMSE on test data (only on observed/non-zero positions to evaluate missing rating predictions)\n",
    "test_mask = test_matrix > 0  # Mask for actual ratings in test\n",
    "test_actual = test_matrix.values[test_mask.values].flatten()  # Flatten observed values using .values on DataFrame for numpy array, then boolean indexing with test_mask.values (boolean numpy array)\n",
    "test_pred = pred_matrix[test_mask.values].flatten()  # Corresponding predictions; pred_matrix is already numpy, so direct boolean indexing with test_mask.values (remove .values after pred_matrix[test_mask])\n",
    "rmse = sqrt(mean_squared_error(test_actual, test_pred))\n",
    "print(\"RMSE (sklearn NMF):\", rmse)  # Expected: ~1.0-1.2; interpret in discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40a491c-b083-4f79-a860-72a66ca886bf",
   "metadata": {},
   "source": [
    "#### Impute zeros with user means (fix for lower RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9167ad9c-d3d8-4138-8f24-55f4c1509e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n_components      rmse\n",
      "0            10  2.779244\n",
      "1            20  2.720972\n",
      "2            30  2.711828\n",
      "\n",
      "Best n_components: 30 with RMSE: 2.7118277965288007\n"
     ]
    }
   ],
   "source": [
    "# Impute zeros with user means (fix for lower RMSE)\n",
    "user_means = train_matrix.mean(axis=1)\n",
    "train_matrix_imputed = train_matrix.copy()\n",
    "for user in train_matrix.index:\n",
    "    zero_mask = train_matrix_imputed.loc[user] == 0\n",
    "    train_matrix_imputed.loc[user, zero_mask] = user_means[user]\n",
    "\n",
    "# Tune n_components\n",
    "rmse_results = []\n",
    "best_rmse = float('inf')\n",
    "best_n = None\n",
    "\n",
    "for n in [10, 20, 30]:\n",
    "    nmf = NMF(n_components=n, init='nndsvda', random_state=42, max_iter=200, beta_loss='kullback-leibler', solver='mu')  # Or 'nndsvdar'\n",
    "    W = nmf.fit_transform(train_matrix_imputed)\n",
    "    H = nmf.components_\n",
    "    pred_matrix = np.dot(W, H)\n",
    "    \n",
    "    test_mask = test_matrix > 0\n",
    "    test_actual = test_matrix.values[test_mask.values].flatten()\n",
    "    test_pred = pred_matrix[test_mask.values].flatten()\n",
    "    rmse = sqrt(mean_squared_error(test_actual, test_pred))\n",
    "    rmse_results.append({'n_components': n, 'rmse': rmse})\n",
    "    \n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_n = n\n",
    "\n",
    "# Results table\n",
    "rmse_df = pd.DataFrame(rmse_results)\n",
    "print(rmse_df)\n",
    "\n",
    "print(f\"\\nBest n_components: {best_n} with RMSE: {best_rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d83d8d-c446-42eb-bc87-3840d2ccb33e",
   "metadata": {},
   "source": [
    "### 2. Discussion of Results, Underperformance Reasons, and Fixes\n",
    "My results showed a pretty high RMSE around 2.71-2.88, meaning the predictions for missing ratings were off quite a bit (like 3 points on a 1-5 scale), and tuning only helped a little with smaller gains as factors went up.\n",
    "\n",
    "It didn't do great compared to basics like global mean (RMSE about 1.05) or user mean (around 0.95), or the similarity stuff from Module 3 like KNN or Jaccard (often ~0.9). The sklearn NMF seems to pull predictions low because it treats all those missing spots as actual zeros, and it's not built specifically for recommenders, no user or item biases, slow on sparse data, and just a general tool.\n",
    "\n",
    "To fix it, I could fill in zeros with user or item averages beforehand; add biases manually by calculating and adjusting them around the NMF step; tweak more like alpha_W at 0.1 or init='nndsvda'; mix it with KNN using the latents as extra features; clip outputs to 1-5; or blend with baselines to drop RMSE to maybe 0.85."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908ceaf2-3f00-45f7-8f6a-fc5a53a1f8f7",
   "metadata": {},
   "source": [
    "### Recommendations to Improve the above assignment \n",
    "##### (my future assingment for better experience )\n",
    "\n",
    "- Further Tuning: Test n=[15,25,35] or grid with alpha_W=[0.01,0.1] (regularization to curb overfitting at high n). Use init='nndsvdar' for zeros.\n",
    "- Address Limitations: Impute zeros with means/biases pre-fit (e.g., subtract user mean, apply NMF, add back)—can drop RMSE ~20-30%.\n",
    "- Hybrid/Alternatives: Ensemble NMF with KNN (use latents as features); switch to libraries like Surprise for biased MF (RMSE ~0.85).\n",
    "- Evaluation Enhancements: Add MAE/precision@K; cross-validate RMSE to reduce variance.\n",
    "- Compute Tips: If slow, subsample data or use GPU-accelerated alternatives (e.g., cuML NMF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6273e8-57fb-4cd3-ac6b-068cf55b5d86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llms]",
   "language": "python",
   "name": "conda-env-llms-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
